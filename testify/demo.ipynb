{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import logging as log\n",
    "import typing as t\n",
    "from moviepy.video.fx.resize import resize\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.basicConfig(level=log.DEBUG \n",
    "                    ,filename=\"demo.log\" \n",
    "                    ,filemode=\"w\" \n",
    "                    ,format=\"%(asctime)s - %(name)s - %(levelname)-9s - %(filename)-8s : %(lineno)s line - %(message)s\" #日志输出的格式\n",
    "                    # -8表示占位符，让输出左对齐，输出长度都为8位\n",
    "                    ,datefmt=\"%Y-%m-%d %H:%M:%S\" \n",
    "                    )\n",
    "\n",
    "log.debug = print\n",
    "log.info = print\n",
    "log.warning = print\n",
    "log.error = print\n",
    "log.critical = print\n",
    "# log.debug('This message should go to the log file')\n",
    "# log.info('So should this')\n",
    "# log.warning('And this, too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame(f: np.ndarray,delay:int = 0) -> None:\n",
    "    # resized.get_frame(0).shape\n",
    "    cv2.imshow(\"frame\", f )\n",
    "    cv2.waitKey(delay)\n",
    "    if delay == 0:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置\n",
    "# video_path = \"D:\\AFSSC\\Documents\\python学习\\视频剪辑项目\\手术原始视频 00_00_00-00_15_00.mp4\"\n",
    "video_path = R\"D:\\AFSSC\\Documents\\python学习\\视频剪辑项目\\手术原始视频.mp4\"\n",
    "template_path = R\"templates\\endoscope.png\"\n",
    "proxy_size = (214, 120)\n",
    "proxy_filename = \"proxy.mp4\"\n",
    "template_threshold = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video:D:\\AFSSC\\Documents\\python学习\\视频剪辑项目\\手术原始视频.mp4 opened.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    log.critical(\"Cannot open video.\")\n",
    "    \n",
    "log.debug(f\"video:{video_path} opened.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_frame = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tplt = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "tplt[np.where(tplt == 0 )] = 0\n",
    "tplt[np.where(tplt == 50 )] = 0\n",
    "tplt[np.where(tplt == 150 )] = 255\n",
    "tplt[np.where(tplt == 250 )] = 0\n",
    "tplt = cv2.resize(tplt,(1280,720))\n",
    "tplt[np.where(tplt != 255 )] = 0\n",
    "# show_frame(tplt,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.heatmap(tplt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_nearby_frames(cap: cv2.VideoCapture, frame: np.ndarray, threshold: int = 50000) -> t.Tuple[int, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Search nearby frames for the one that is most similar to the given frame.\n",
    "    \"\"\"\n",
    "    min_diff = threshold\n",
    "    min_frame = None\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    for i in tqdm.tqdm(range(int(total_frame))):\n",
    "        ret, f = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        diff = cv2.absdiff(frame, f)\n",
    "        diff = np.sum(diff)\n",
    "        if diff < min_diff:\n",
    "            min_diff = diff\n",
    "            min_frame = f\n",
    "    return min_diff, min_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking(f,msk):\n",
    "    # f = cv2.resize(f, (tplt.shape[1], tplt.shape[0]))\n",
    "    msk = cv2.cvtColor(msk, cv2.COLOR_GRAY2BGR)\n",
    "    f = cv2.bitwise_and(f, msk)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 114514)\n",
    "testframe1  = cap.read()[1]\n",
    "standard = testframe1\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 444444)\n",
    "testframe2  = cap.read()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = cv2.SIFT.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1 , des1 = algo.detectAndCompute(testframe1, tplt)\n",
    "kp2 , des2 = algo.detectAndCompute(testframe2, tplt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "# matches = bf.match(des1)\n",
    "# matches = sorted(matches, key=lambda val: val.distance)\n",
    "result = cv2.drawMatchesKnn(testframe1, kp1, testframe2, kp2, matches[:50], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1397"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1397"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "291.36851185803425"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_distance = 0\n",
    "count = 0\n",
    "for m,n in matches:\n",
    "    total_distance +=m.distance\n",
    "    count+=1\n",
    "display(count,len(matches))\n",
    "display(total_distance/(count if count else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo = cv2.SIFT.create()\n",
    "algo = cv2.ORB.create()\n",
    "matcher = cv2.BFMatcher()\n",
    " \n",
    "kpstd, desstd = algo.detectAndCompute(standard, tplt)\n",
    "def calculate_knn_distance(src_index:int) -> float:\n",
    "    global cap\n",
    "    global tplt\n",
    "    global algo\n",
    "    global matcher\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES,src_index)\n",
    "    src = cap.read()[1]\n",
    "    kpsrc , dessrc = algo.detectAndCompute(src,tplt)\n",
    "    matches = matcher.knnMatch(dessrc,desstd,k=2)\n",
    "    total_distance = 0\n",
    "    count = 0\n",
    "    for m,n in matches:\n",
    "        total_distance +=m.distance\n",
    "        count+=1\n",
    "    return total_distance/count if count else 0\n",
    "\n",
    "    # raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ssim(image1, image2):\n",
    "    # 将图像转换为灰度图像\n",
    "    gray_image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    # 计算SSIM\n",
    "    show_frame(gray_image1)\n",
    "    show_frame(gray_image2)\n",
    "    score, _ = ssim(gray_image1, gray_image2, full=True)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "similarity_threshold=0.5\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "similar_frames = []\n",
    "\n",
    "calculate_ssim(testframe1,testframe2)\n",
    "\n",
    "# for i in tqdm.tqdm(range(114514 - 5000, 114514 + 5000, 50)):\n",
    "#     cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     for j in range(i + 1, frame_count, 50):\n",
    "#         cap.set(cv2.CAP_PROP_POS_FRAMES, j)\n",
    "#         ret, next_frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "#         similarity culate_ssim(frame, next_frame)\n",
    "#         if similarity > similarity_threshold:\n",
    "#             similar_frames.append((i, j))\n",
    "\n",
    "# cap.release()\n",
    "\n",
    "\n",
    "#\n",
    "print(similar_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:15<00:00, 12.81it/s]\n"
     ]
    }
   ],
   "source": [
    "off = 500000\n",
    "score =  []\n",
    "for i in tqdm.tqdm(range(114514 - off , 114514 + off ,5000)):\n",
    "    score.append(calculate_knn_distance(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b9d4651840>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = cv2.resize(result, (result.shape[1]*4, result.shape[0]*4))\n",
    "imgmatches = cv2.drawMatchesKnn(testframe1, kp1, testframe2, kp2, goodmatches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "show_frame(imgmatches,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_frame(tplt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2 crude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tplt = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "tplt[np.where(tplt == 0 )] = 1\n",
    "tplt[np.where(tplt == 50 )] = 0\n",
    "tplt[np.where(tplt == 150 )] = 0\n",
    "tplt[np.where(tplt == 250 )] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_match_score(src: np.ndarray,template: np.ndarray,lower_thresh:int) -> int:\n",
    "    return (template*src).sum() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crude_search_preprocess(frame: np.ndarray) -> np.ndarray:\n",
    "    frame = cv2.resize(frame, proxy_size, None)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.GaussianBlur(frame,(5,5),0)\n",
    "    frame = cv2.dilate(frame, None, iterations=2)\n",
    "    frame = cv2.threshold(frame, 30, None, cv2.THRESH_TOZERO, None)[1]\n",
    "    frame = frame // 10\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:10<00:00, 18.39it/s]\n"
     ]
    }
   ],
   "source": [
    "match_score = [] \n",
    "match_frame = []\n",
    "match_edges = []\n",
    "tgt_frame_num = 200 \n",
    "step = int(total_frame//tgt_frame_num)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "last_judge = False\n",
    "last_frame = 0\n",
    "\n",
    "for i in tqdm.tqdm(range(0,int(total_frame),step)):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = crude_search_preprocess(frame)\n",
    "    score = calculate_match_score(frame,tplt,template_threshold)\n",
    "    match_score.append(score)\n",
    "    match_frame.append(i - step)\n",
    "    if last_judge ^ (score < template_threshold):\n",
    "        match_edges.append((last_frame - step,i - step,True if last_judge else False))\n",
    "    last_judge = score < template_threshold\n",
    "    last_frame = i\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "\n",
    "    # show_frame(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12204, 18306, False), (189162, 195264, True), (414936, 421038, False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(start_index: int, end_index: int ,is_upside:bool,cap: cv2.VideoCapture, \n",
    "                  template: np.ndarray, template_threshold: int) -> int:\n",
    "    l = start_index \n",
    "    h = end_index\n",
    "    # print(f\"h:{h},l:{l}\")\n",
    "    while(h - l > 1):\n",
    "        # print(f\"h:{h},l:{l}\")\n",
    "        m = (h+l)//2\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, m)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = crude_search_preprocess(frame)\n",
    "        # show_frame(frame)\n",
    "        score = calculate_match_score(frame,template,template_threshold)\n",
    "        log.debug(f\"m:{m},score:{score},judge:{score < template_threshold}\")\n",
    "        if is_upside:\n",
    "            if score > template_threshold:\n",
    "                h = m\n",
    "            else:\n",
    "                l = m\n",
    "        else:\n",
    "            if score > template_threshold:\n",
    "                l = m\n",
    "            else:\n",
    "                h = m\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:15255,score:118266,judge:False\n",
      "m:16780,score:30057,judge:True\n",
      "m:16017,score:116560,judge:False\n",
      "m:16398,score:117192,judge:False\n",
      "m:16589,score:32098,judge:True\n",
      "m:16493,score:118072,judge:False\n",
      "m:16541,score:117962,judge:False\n",
      "m:16565,score:31628,judge:True\n",
      "m:16553,score:95194,judge:False\n",
      "m:16559,score:61895,judge:False\n",
      "m:16562,score:43688,judge:True\n",
      "m:16560,score:54409,judge:False\n",
      "m:16561,score:44724,judge:True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16561"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(*match_edges[0],cap,tplt,template_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 16561)\n",
    "ret, f = cap.read()\n",
    "show_frame(f,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.set(cv2.CAP_PROP_POS_FRAMES, match_score[68])\n",
    "ret, f = cap.read()\n",
    "show_frame(f,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dc028e3b50>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(match_frame,match_score)\n",
    "# plt.plot(match_score)\n",
    "# a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### moviepy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = VideoFileClip(video_path,pix_fmt='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = resize(video,proxy_size)\n",
    "\n",
    "duration = resized.duration\n",
    "fps = resized.fps\n",
    "n_frames = int(duration * fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 214, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized.get_frame(899).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m show_frame(\u001b[43mframes\u001b[49m[\u001b[38;5;241m3\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frames' is not defined"
     ]
    }
   ],
   "source": [
    "show_frame(frames[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(frame):\n",
    "    # 使用颜色直方图作为特征\n",
    "    hist = cv2.calcHist([frame], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()\n",
    "\n",
    "def calculate_similarity(hist1, hist2):\n",
    "    # 使用巴氏距离计算相似度\n",
    "    return cv2.compareHist(hist1, hist2, cv2.HISTCMP_BHATTACHARYYA)\n",
    "\n",
    "def segment_video(video_path, threshold=0.5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Cannot open video.\")\n",
    "        return\n",
    "\n",
    "    segments = []\n",
    "    prev_hist = None\n",
    "    segment_start = 0\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        hist = extract_features(frame)\n",
    "        if prev_hist is not None:\n",
    "            similarity = calculate_similarity(prev_hist, hist)\n",
    "            if similarity > threshold:\n",
    "                segments.append((segment_start, frame_count))\n",
    "                segment_start = frame_count + 1\n",
    "\n",
    "        prev_hist = hist\n",
    "        frame_count += 1\n",
    "\n",
    "    segments.append((segment_start, frame_count))\n",
    "    cap.release()\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"../\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SurgeryAutoClip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
